# Retail ETL Data Pipeline using Azure & Delta Lake (Medallion Architecture)

## Project Overview
This project builds an end-to-end ETL pipeline for the Retail domain using modern data engineering practices.
The pipeline ingests raw data from multiple sources, transforms it into a clean, standardized format, and loads it into a data warehouse for business reporting and analytics.

## Business Problem / Objective
- **Problem**: Retail data was scattered across multiple systems (ADLS, SQL DB, APIs), making consolidated reporting difficult.
- **Objective**:
    - Automate data ingestion from multiple sources.
    - Apply robust transformations and data modeling.
    - Deliver **business-ready datasets** for BI dashboards and decision-making.

## Key Features
 ðŸ”¹ **Incremental Loading** â†’ Implemented watermark strategy to load only new/changed data.
 ðŸ”¹ **Delta Lake** â†’ Used for ACID transactions, schema enforcement, and schema evolution.
 ðŸ”¹ **SCD Type 1 & Type 2** â†’ Managed Slowly Changing Dimensions to handle historical customer & product data.
 ðŸ”¹ **Star Schema** â†’ Designed a dimensional model with Fact & Dimension tables for analytics.
 ðŸ”¹ **Partitioning & Optimization** â†’ Improved performance using partitioning, Z-ordering, and broadcast joins in PySpark.
 ðŸ”¹ **Medallion Architecture (Bronze â†’ Silver â†’ Gold)** â†’
    - **Bronze**: Raw ingested data from CSV, SQL DB, and APIs.
    - **Silver**: Cleaned, deduplicated, standardized data with business rules.
    - **Gold**: Curated fact & dimension tables for BI consumption.

## Architecture overview
<img width="1742" height="886" alt="arc" src="https://github.com/user-attachments/assets/a694eb2d-505c-42f3-ac85-112c575ce606" />

## ETL Flow
1. **Extract** â€“ Ingest raw data into Bronze layer.
2. **Transform** â€“ Clean, deduplicate, apply business rules in Silver layer.
3. **Load** â€“ Build fact & dimension tables in Gold layer for analytics.

## Data Model (Star Schema)

## Technologies Used
- **Azure Data Factory** â†’ Pipeline orchestration
- **Azure Data Lake Storage** â†’ Bronze/Silver/Gold layers
- **Azure Databricks (PySpark)** â†’ Data transformations
- **Delta Lake** â†’ ACID + schema evolution
- **Azure Synapse Analytics** â†’ Data warehouse
- **Power BI** â†’ BI dashboards

## Challenges & Solutions


## Results
- Automated **daily ETL pipeline** with **incremental loading**.
- Centralized **retail data mart** with Sales, Inventory, and Customer tables.
- Power BI dashboards with KPIs: **Revenue, Profit Margin, Inventory Turnover**.
